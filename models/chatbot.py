# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dG7798PTI5g0vkeVUZ_f9xyjJHyU1q1j
"""

import torch
from transformers import BertTokenizer, BertForSequenceClassification
import random

class BERTOutputAnalyzer:
    def __init__(self, model_name='bert-base-uncased'):
        """
        Initialize BERT model for sequence classification

        Args:
            model_name (str): Pretrained BERT model name
        """
        # Load pretrained model and tokenizer
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = BertForSequenceClassification.from_pretrained(model_name)

        # Define class labels (example for sentiment analysis)
        self.class_labels = ['Negative', 'Neutral', 'Positive']

        # Define random messages for security risks
        self.risk_messages = [
            "Nice try! But we've seen this one before... 🕵️",
            "Hmm... getting a bit creative there, aren't we? 🤔",
            "What do you call that? Amateur hour? 😏",
            "Oh look, another sneaky attempt! How original... 🎭",
            "Did you really think that would work? 🤣",
            "Congratulations! You've won... absolutely nothing! 🏆",
            "Error 404: Hack not found 🚫",
            "That's cute. Keep trying! 😉",
            "Plot twist: We saw that coming! 🎬",
            "Breaking news: Security still works! 📰",
            "Your attempt has been logged... and laughed at 📝",
            "Sorry, we don't serve that kind of request here 🚫",
            "Is that the best you've got? 💪",
            "Thanks for the entertainment! 🎪",
            "Loading hack.exe... just kidding! 🖥️"
        ]

    def analyze_text(self, input_text: str) -> dict:
        """
        Perform text analysis and return comprehensive results

        Args:
            input_text (str): Text to analyze

        Returns:
            dict: Comprehensive analysis results
        """
        # Tokenize and encode input
        inputs = self.tokenizer(
            input_text,
            return_tensors='pt',
            truncation=True,
            max_length=512,
            padding='max_length'
        )

        # Perform inference
        with torch.no_grad():
            outputs = self.model(**inputs)

        # Process model outputs
        probabilities = torch.softmax(outputs.logits, dim=1)
        predicted_class_idx = torch.argmax(probabilities, dim=1)

        # Prepare detailed analysis
        analysis_result = {
            'input_text': input_text,
            'predicted_class': self.class_labels[predicted_class_idx],
            'confidence_scores': {
                label: prob.item()
                for label, prob in zip(self.class_labels, probabilities[0])
            },
            'tokens': {
                'total_tokens': len(inputs['input_ids'][0]),
                'input_ids': inputs['input_ids'][0].tolist(),
                'attention_mask': inputs['attention_mask'][0].tolist()
            },
            'security_insights': self._perform_security_checks(input_text)
        }

        return analysis_result

    def _perform_security_checks(self, text: str) -> dict:
        """
        Perform basic security checks on input text

        Args:
            text (str): Input text to check

        Returns:
            dict: Security analysis results
        """
        security_risks = {
            'injection_risk': False,
            'special_char_count': 0,
            'length_risk': False,
            'risk_message': ''
        }

        # Injection risk detection
        injection_keywords = [
    'bypass', 'circumvent', 'evade','passkey', 'escape','key', 'avoid', 'dodge', 'sidestep', 'skirt', 'elude', 'shun',
    'alter', 'change', 'modify', 'adjust', 'tweak', 'amend', 'revise', 'update', 'transform', 'convert',
    'manipulate', 'control', 'handle', 'operate', 'use', 'exploit', 'utilize', 'employ', 'apply', 'implement',
    'override', 'overrule', 'disregard', 'neglect', 'omit', 'pass over', 'skip', 'leap', 'jump', 'vault',
    'hack', 'crack', 'break', 'penetrate', 'pierce', 'invade', 'enter', 'access', 'gain entry', 'intrude',
    'debug', 'fix', 'repair', 'mend', 'correct', 'rectify', 'amend', 'patch', 'upgrade', 'enhance',
    'customize', 'personalize', 'tailor', 'adapt', 'fit', 'suit', 'accommodate', 'conform', 'comply', 'obey',
    'cheat', 'deceive', 'trick', 'fool', 'hoodwink', 'dupe', 'swindle', 'defraud', 'con', 'scam',
    'forge', 'fabricate', 'fake', 'counterfeit', 'imitate', 'mimic', 'copy', 'duplicate', 'reproduce', 'clone',
    'emulate', 'mirror', 'reflect', 'echo', 'repeat', 'reiterate', 'restate', 'rephrase', 'paraphrase', 'summarize',
    'alter', 'change', 'modify', 'adjust', 'tweak', 'amend', 'revise', 'update', 'transform', 'convert',
    'manipulate', 'control', 'handle', 'operate', 'use', 'exploit', 'utilize', 'employ', 'apply', 'implement',
    'override', 'overrule', 'disregard', 'neglect', 'omit', 'pass over', 'skip', 'leap', 'jump', 'vault',
    'hack', 'crack', 'break', 'penetrate', 'pierce', 'invade', 'enter', 'access', 'gain entry', 'intrude',
    'debug', 'fix', 'repair', 'mend', 'correct', 'rectify', 'amend', 'patch', 'upgrade', 'enhance',
    'customize', 'personalize', 'tailor', 'adapt', 'fit', 'suit', 'accommodate', 'conform', 'comply', 'obey',
    'cheat', 'deceive', 'trick', 'fool', 'hoodwink', 'dupe', 'swindle', 'defraud', 'con', 'scam',
    'forge', 'fabricate', 'fake', 'counterfeit', 'imitate', 'mimic', 'copy', 'duplicate', 'reproduce', 'clone',
    'emulate', 'mirror', 'reflect', 'echo', 'repeat', 'reiterate', 'restate', 'rephrase', 'paraphrase', 'summarize',
    'alter', 'change', 'modify', 'adjust', 'tweak', 'amend', 'revise', 'update', 'transform', 'convert',
    'manipulate', 'control', 'handle', 'operate', 'use', 'exploit', 'utilize', 'employ', 'apply', 'implement',
    'override', 'overrule', 'disregard', 'neglect', 'omit', 'pass over', 'skip', 'leap', 'jump', 'vault',
    'hack', 'crack', 'break', 'penetrate', 'pierce', 'invade', 'enter', 'access', 'gain entry', 'intrude',
    'debug', 'fix', 'repair', 'mend', 'correct', 'rectify', 'amend', 'patch', 'upgrade', 'enhance',
    'customize', 'personalize', 'tailor', 'adapt', 'fit', 'suit', 'accommodate', 'conform', 'comply', 'obey',
    'cheat', 'deceive', 'trick', 'fool', 'hoodwink', 'dupe', 'swindle', 'defraud', 'con', 'scam',
    'forge', 'fabricate', 'fake', 'counterfeit', 'imitate', 'mimic', 'copy', 'duplicate', 'reproduce', 'clone',
    'emulate', 'mirror', 'reflect', 'echo', 'repeat', 'reiterate', 'restate', 'rephrase', 'paraphrase', 'summarize',
    'alter', 'change', 'modify', 'adjust', 'tweak', 'amend', 'revise', 'update', 'transform', 'convert',
    'manipulate', 'control', 'handle', 'operate', 'use', 'exploit', 'utilize', 'employ', 'apply', 'implement',
    'override', 'overrule', 'disregard', 'neglect', 'omit', 'pass over', 'skip', 'leap', 'jump', 'vault',
    'hack', 'crack', 'break', 'penetrate', 'pierce', 'invade', 'enter', 'access', 'gain entry', 'intrude',
    'debug', 'fix', 'repair', 'mend', 'correct', 'rectify', 'amend', 'patch', 'upgrade', 'enhance',
    'customize', 'personalize', 'tailor', 'adapt', 'fit', 'suit', 'accommodate', 'conform', 'comply', 'obey',
    'cheat', 'deceive', 'trick', 'fool', 'hoodwink', 'dupe', 'swindle', 'defraud', 'con', 'scam',
    'forge', 'fabricate', 'fake', 'counterfeit', 'imitate', 'mimic', 'copy', 'duplicate', 'reproduce', 'clone',
    'emulate', 'mirror', 'reflect', 'echo', 'repeat', 'reiterate', 'restate', 'rephrase', 'paraphrase', 'summarize'
]
        security_risks['injection_risk'] = any(
            keyword in text.lower()
            for keyword in injection_keywords
        )

        # Add random message if injection risk detected
        if security_risks['injection_risk']:
            security_risks['risk_message'] = random.choice(self.risk_messages)

        # Special character count
        import re
        special_chars = re.findall(r'[^a-zA-Z0-9\s]', text)
        security_risks['special_char_count'] = len(special_chars)

        # Length risk (too short or too long)
        security_risks['length_risk'] = len(text) < 3 or len(text) > 1000

        # Add additional message for high special character count
        if security_risks['special_char_count'] > 5:
            special_char_messages = [
                "Wow, someone's feeling special... character happy! ✨",
                "Did your keyboard just sneeze? 🤧",
                "Special characters party detected! 🎉"
            ]
            if security_risks['risk_message']:
                security_risks['risk_message'] += "\n" + random.choice(special_char_messages)
            else:
                security_risks['risk_message'] = random.choice(special_char_messages)

        return security_risks

def main():
    # Initialize the analyzer
    analyzer = BERTOutputAnalyzer()
    text = input("Enter the message: ")

    # Example texts to analyze
    test_texts = [text]

    # Analyze each text
    for text in test_texts:
        print("\n--- Text Analysis ---")
        result = analyzer.analyze_text(text)

        # Pretty print the result
        print(f"Input Text: {result['input_text']}")
        print("\nSecurity Insights:")
        for risk, value in result['security_insights'].items():
            if risk != 'risk_message':  # Print regular risks normally
                print(f"  {risk}: {value}")

        # Print risk message if it exists
        if result['security_insights']['risk_message']:
            print("\n" + result['security_insights']['risk_message'])


if __name__ == "__main__":
    main()